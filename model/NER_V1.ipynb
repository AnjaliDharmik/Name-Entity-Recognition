{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0iaCxQam6-i"
      },
      "source": [
        "# Set Up\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEcoeIBBouey",
        "outputId": "ec7cdb8e-9aef-402e-e958-c8d7be389ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxSAhQBamx9T"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification,AutoModelForCausalLM, TokenClassificationPipeline, \\\n",
        "GenerationConfig, pipeline, BitsAndBytesConfig , CodeGenTokenizer\n",
        "\n",
        "from Utils import *\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\n",
        "metrics_df = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6wmnxKVoPR0"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RliVMP5oP2Q"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Train_Data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "0CBbrG2bDuEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzfSddZK4uWJ"
      },
      "outputs": [],
      "source": [
        "#df = df.sample(n=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ymIR67SNV5V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaFF_YSXoYvv"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade tensorflow\n"
      ],
      "metadata": {
        "id": "pB_VvtRj04hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Detect TPU if available\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    print(\"TPU not found\")\n",
        "\n",
        "# Check available devices\n",
        "print(tf.config.list_physical_devices())\n"
      ],
      "metadata": {
        "id": "4ALEqEXlz_5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ULrJohJlrwN"
      },
      "source": [
        "# Phi-2 Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzDesM_eltkS"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")\n",
        "\n",
        "#quantization_config = BitsAndBytesConfig(llm_int8_enable_fp32_cpu_offload=True)\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/phi-2\",\n",
        "    torch_dtype=torch.float32,\n",
        "    device_map='auto'\n",
        "    #quantization_config=quantization_config\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr0Z-vM2l5N9"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=base_model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=256,\n",
        "    temperature=0.6,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.2\n",
        ")\n",
        "local_llm = HuggingFacePipeline(pipeline=pipe)\n",
        "pipe.model.config.pad_token_id = pipe.model.config.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwUVNRESl7RE"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"A virtual assistant answers questions from a user based on the provided text.\n",
        "             identify and generate list of all NOUN type word in the text.\n",
        "              USER: Text: {input_text}\n",
        "              ASSISTANT:\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"instruction\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZPi07B0l_FT"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(text,llm_chain):\n",
        "\n",
        "    result = llm_chain.invoke(text)['text']\n",
        "    answer = [i.replace(\"\\'\",\"\") for i in re.findall(r\"\\'.[a-zA-Z ]+?\\'\", result)]\n",
        "    return answer\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt,\n",
        "                     llm=local_llm\n",
        "                     )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3rnH8eemBUI"
      },
      "outputs": [],
      "source": [
        "df['Phi2_Keywords']=df['Description'].apply(generate_prompt,llm_chain=llm_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXiFsF5RmHTm"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"Phi2_Baseline_Data_Predicted.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQGtEZw9mVBV"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-I_7wSImWOH"
      },
      "outputs": [],
      "source": [
        "processed_phi2_base_df = Data_Mapping(df,'Description','Keywords','Phi2_Keywords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DqDD1hgnJJD"
      },
      "outputs": [],
      "source": [
        "processed_phi2_base_df = Data_Labelling(processed_phi2_base_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZdEfoiWnRJ4"
      },
      "outputs": [],
      "source": [
        "#accuracy, precision, recall and F1\n",
        "model_name = \"Phi-2 Base\"\n",
        "metrics_df = compute_performance_metrics(metrics_df,processed_phi2_base_df,model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUp6pRMj6hgq"
      },
      "source": [
        "# Phi-2 IOB Annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCB9bvhj6lJ7"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"A virtual assistant answers questions from a user based on the provided text.\n",
        "             identify and generate list of all NOUN type word consider (Inside, Outside, Beginning) using in the text.\n",
        "              USER: Text: {input_text}\n",
        "              ASSISTANT:\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"instruction\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZMAqNQs6q0o"
      },
      "outputs": [],
      "source": [
        "llm_chain = LLMChain(prompt=prompt,\n",
        "                     llm=local_llm\n",
        "                     )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tnnRxPl6s-Q"
      },
      "outputs": [],
      "source": [
        "df['Phi2_IOB_Keywords']=df['Description'].apply(generate_prompt,llm_chain=llm_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5eWcf6T6zs0"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"Phi2_IOB_Annotation_Predicted.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CNUuJ7865hy"
      },
      "outputs": [],
      "source": [
        "processed_Phi2_IOB_df = Data_Mapping(df,'Description','Keywords','Phi2_IOB_Keywords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWuvqYA-68l5"
      },
      "outputs": [],
      "source": [
        "processed_Phi2_IOB_df = Data_Labelling(processed_Phi2_IOB_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWCls1oH7RW3"
      },
      "outputs": [],
      "source": [
        "# Compute accuracy,precision, recall, and F1 score\n",
        "model_name = \"Phi-2 IOB Annotation\"\n",
        "metrics_df = compute_performance_metrics(metrics_df,processed_Phi2_IOB_df,model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ9V4VmfnGpR"
      },
      "source": [
        "# BERT BASE Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7T0bKwp-nHHT"
      },
      "outputs": [],
      "source": [
        "model_name = \"QCRI/bert-base-multilingual-cased-pos-english\"\n",
        "\n",
        "# tokenize\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Token Classification\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "\n",
        "# Pipeline\n",
        "pipeline = TokenClassificationPipeline(model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TA_JT3dozB0"
      },
      "outputs": [],
      "source": [
        "def Predict_Keywords(text):\n",
        "  word_list= [i['word'] for i in pipeline(text) if i['entity'] in ['NN']]\n",
        "\n",
        "  result = []\n",
        "  if len(word_list) > 1:\n",
        "    for index, word in enumerate(word_list):\n",
        "        if \"#\" in word:\n",
        "            try:\n",
        "              result[-1] += word[2:]\n",
        "            except:\n",
        "              pass\n",
        "        else:\n",
        "            result.append(word)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XzAx8RXngdz"
      },
      "outputs": [],
      "source": [
        "df['BERT_Keywords']=df['Description'].apply(Predict_Keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cq__mGNtNk5"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"BERT_Baseline_Data_Predicted.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXu63gML2dyA"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WD2t7n4ltazK"
      },
      "outputs": [],
      "source": [
        "processed_BERT_df = Data_Mapping(df,'Description','Keywords','BERT_Keywords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQeYrCjctfVJ"
      },
      "outputs": [],
      "source": [
        "processed_BERT_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZ-9Ett_tlC-"
      },
      "outputs": [],
      "source": [
        "processed_BERT_df = Data_Labelling(processed_BERT_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UklOtUwttnYp"
      },
      "outputs": [],
      "source": [
        "# Compute accuracy,precision, recall, and F1 score\n",
        "model_name = \"BERT Base\"\n",
        "metrics_df = compute_performance_metrics(metrics_df,processed_BERT_df,model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRhHc0EAZm9_"
      },
      "source": [
        "# BERT with IOB tagging Annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcKDZp93Z5of"
      },
      "outputs": [],
      "source": [
        "df['BIO_tags'] = df['Description'].apply(DataAnnotate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4XX8CdzZ7Yt"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1uUJhEcZ9pm"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"IOB_Annotated_Data.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFgD6awGaE2s"
      },
      "outputs": [],
      "source": [
        "processed_BERT_iob_df = Data_Mapping_IOB(df,'Description','Keywords','BIO_tags')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLKUDOwaaGau"
      },
      "outputs": [],
      "source": [
        "processed_BERT_iob_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIttVScxaH7r"
      },
      "outputs": [],
      "source": [
        "processed_BERT_iob_df = Data_Labelling(processed_BERT_iob_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmzbqJ-qaKSS"
      },
      "outputs": [],
      "source": [
        "#accuracy, precision, recall and F1\n",
        "model_name = \"BERT IOB Annotation\"\n",
        "metrics_df = compute_performance_metrics(metrics_df,processed_BERT_iob_df,model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbpk_2v8nW6T"
      },
      "outputs": [],
      "source": [
        "metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKJVKEt-jntB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}